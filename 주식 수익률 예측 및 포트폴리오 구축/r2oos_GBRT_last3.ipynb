{"cells":[{"cell_type":"code","execution_count":null,"id":"9e404323","metadata":{"id":"9e404323","outputId":"957a7177-cd51-4f6c-d09f-73832feb35f2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>yearmonth</th>\n","      <th>Ticker</th>\n","      <th>한국표준산업분류코드10차(중분류)</th>\n","      <th>수익률 (1개월)(%)</th>\n","      <th>베타 (D,1Yr)</th>\n","      <th>PER(배)</th>\n","      <th>PSR(배)</th>\n","      <th>chmom</th>\n","      <th>mom36m</th>\n","      <th>zerotrade</th>\n","      <th>...</th>\n","      <th>원/달러환율</th>\n","      <th>금($/OZ)</th>\n","      <th>뉴스심리지수</th>\n","      <th>KOSPI dp</th>\n","      <th>KOSPI PER</th>\n","      <th>KOSPI PBR</th>\n","      <th>CD Rate</th>\n","      <th>Term spread</th>\n","      <th>Default Spread</th>\n","      <th>VKOSPI 200</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2004-01</td>\n","      <td>A005930</td>\n","      <td>26</td>\n","      <td>1.87</td>\n","      <td>0.756757</td>\n","      <td>-0.133333</td>\n","      <td>0.670270</td>\n","      <td>-0.084685</td>\n","      <td>0.812613</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>1172.1</td>\n","      <td>402.45</td>\n","      <td>100.0</td>\n","      <td>1.99</td>\n","      <td>10.72</td>\n","      <td>1.07</td>\n","      <td>4.26</td>\n","      <td>1.16</td>\n","      <td>4.32</td>\n","      <td>21.23</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004-02</td>\n","      <td>A005930</td>\n","      <td>26</td>\n","      <td>4.95</td>\n","      <td>0.764388</td>\n","      <td>-0.124101</td>\n","      <td>0.688849</td>\n","      <td>-0.383094</td>\n","      <td>0.879496</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>1171.6</td>\n","      <td>396.15</td>\n","      <td>100.0</td>\n","      <td>1.99</td>\n","      <td>10.94</td>\n","      <td>1.08</td>\n","      <td>4.08</td>\n","      <td>1.35</td>\n","      <td>4.40</td>\n","      <td>19.95</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004-03</td>\n","      <td>A005930</td>\n","      <td>26</td>\n","      <td>-0.54</td>\n","      <td>0.861261</td>\n","      <td>-0.072072</td>\n","      <td>0.713514</td>\n","      <td>0.623423</td>\n","      <td>0.846847</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>1153.3</td>\n","      <td>426.45</td>\n","      <td>100.0</td>\n","      <td>1.83</td>\n","      <td>11.19</td>\n","      <td>1.11</td>\n","      <td>3.93</td>\n","      <td>1.33</td>\n","      <td>4.48</td>\n","      <td>24.66</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004-04</td>\n","      <td>A005930</td>\n","      <td>26</td>\n","      <td>-9.16</td>\n","      <td>0.905626</td>\n","      <td>-0.081670</td>\n","      <td>0.709619</td>\n","      <td>-0.618875</td>\n","      <td>0.809437</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>1170.7</td>\n","      <td>386.75</td>\n","      <td>100.0</td>\n","      <td>2.21</td>\n","      <td>16.76</td>\n","      <td>1.10</td>\n","      <td>3.91</td>\n","      <td>1.34</td>\n","      <td>4.47</td>\n","      <td>24.47</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004-05</td>\n","      <td>A005930</td>\n","      <td>26</td>\n","      <td>-8.27</td>\n","      <td>0.881081</td>\n","      <td>-0.079279</td>\n","      <td>0.720721</td>\n","      <td>-0.621622</td>\n","      <td>0.881081</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>1164.9</td>\n","      <td>395.55</td>\n","      <td>100.0</td>\n","      <td>2.39</td>\n","      <td>15.40</td>\n","      <td>1.02</td>\n","      <td>3.90</td>\n","      <td>1.26</td>\n","      <td>4.47</td>\n","      <td>30.14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>"],"text/plain":["  yearmonth   Ticker  한국표준산업분류코드10차(중분류)  수익률 (1개월)(%)  베타 (D,1Yr)    PER(배)  \\\n","0   2004-01  A005930                  26          1.87    0.756757 -0.133333   \n","1   2004-02  A005930                  26          4.95    0.764388 -0.124101   \n","2   2004-03  A005930                  26         -0.54    0.861261 -0.072072   \n","3   2004-04  A005930                  26         -9.16    0.905626 -0.081670   \n","4   2004-05  A005930                  26         -8.27    0.881081 -0.079279   \n","\n","     PSR(배)     chmom    mom36m  zerotrade  ...  원/달러환율  금($/OZ)  뉴스심리지수  \\\n","0  0.670270 -0.084685  0.812613       -1.0  ...  1172.1   402.45   100.0   \n","1  0.688849 -0.383094  0.879496       -1.0  ...  1171.6   396.15   100.0   \n","2  0.713514  0.623423  0.846847       -1.0  ...  1153.3   426.45   100.0   \n","3  0.709619 -0.618875  0.809437       -1.0  ...  1170.7   386.75   100.0   \n","4  0.720721 -0.621622  0.881081       -1.0  ...  1164.9   395.55   100.0   \n","\n","   KOSPI dp  KOSPI PER  KOSPI PBR  CD Rate  Term spread  Default Spread  \\\n","0      1.99      10.72       1.07     4.26         1.16            4.32   \n","1      1.99      10.94       1.08     4.08         1.35            4.40   \n","2      1.83      11.19       1.11     3.93         1.33            4.48   \n","3      2.21      16.76       1.10     3.91         1.34            4.47   \n","4      2.39      15.40       1.02     3.90         1.26            4.47   \n","\n","   VKOSPI 200  \n","0       21.23  \n","1       19.95  \n","2       24.66  \n","3       24.47  \n","4       30.14  \n","\n","[5 rows x 34 columns]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv('C:/Users/연구실/연구실 프로젝트/data/전처리최종이었음좋겠다.csv')\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"53422771","metadata":{"id":"53422771"},"outputs":[],"source":["X = data.drop(['한국표준산업분류코드10차(중분류)', '수익률 (1개월)(%)', '뉴스심리지수'], axis=1)\n","y = data['수익률 (1개월)(%)']\n","ym = data['yearmonth']\n","tk = data['Ticker']"]},{"cell_type":"code","execution_count":null,"id":"42c44e94","metadata":{"scrolled":true,"id":"42c44e94","outputId":"c87b3b68-0b48-4f61-88d4-17b2cb44fc0e"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                        | 1/1000 [38:29<641:00:47, 2309.96s/trial, best loss: 0.08130817854062489]\u001b[A\n","  0%|                                        | 2/1000 [58:52<463:06:37, 1670.54s/trial, best loss: 0.08130817854062489]\u001b[A\n","  0%|                                     | 3/1000 [1:03:02<282:55:42, 1021.61s/trial, best loss: 0.001065767746173396]\u001b[A\n","  0%|▏                                     | 4/1000 [1:15:27<252:24:56, 912.35s/trial, best loss: 0.001065767746173396]\u001b[A\n","  0%|▏                                    | 5/1000 [1:23:07<207:09:47, 749.54s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▏                                    | 6/1000 [1:42:28<245:31:32, 889.23s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▎                                   | 7/1000 [2:30:42<426:02:32, 1544.56s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▎                                   | 8/1000 [2:44:57<365:10:28, 1325.23s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▎                                   | 9/1000 [3:27:01<467:56:35, 1699.89s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▎                                  | 10/1000 [3:42:53<403:57:49, 1468.96s/trial, best loss: 0.0010305827218730634]\u001b[A\n","  1%|▍                                  | 11/1000 [3:45:48<294:47:50, 1073.07s/trial, best loss: -0.022526003591763266]\u001b[A\n","  1%|▍                                  | 12/1000 [4:24:06<396:45:31, 1445.68s/trial, best loss: -0.022526003591763266]\u001b[A\n","  1%|▍                                  | 13/1000 [4:46:43<388:58:10, 1418.73s/trial, best loss: -0.022526003591763266]\u001b[A\n","  1%|▍                                  | 14/1000 [4:55:43<315:51:09, 1153.21s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▌                                  | 15/1000 [5:19:57<340:20:31, 1243.89s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▌                                  | 16/1000 [6:17:26<521:24:33, 1907.60s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▌                                  | 17/1000 [7:05:55<603:09:06, 2208.90s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▋                                  | 18/1000 [7:17:08<476:36:42, 1747.25s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▋                                  | 19/1000 [7:38:51<439:47:01, 1613.89s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▋                                  | 20/1000 [8:09:35<458:07:50, 1682.93s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▋                                  | 21/1000 [8:18:23<363:26:52, 1336.48s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▊                                  | 22/1000 [8:27:11<297:07:59, 1093.74s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▊                                  | 23/1000 [8:51:08<324:47:17, 1196.76s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▊                                   | 24/1000 [8:59:56<270:02:24, 996.05s/trial, best loss: -0.022526003591763266]\u001b[A\n","  2%|▉                                   | 25/1000 [9:02:36<201:48:07, 745.12s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|▉                                   | 26/1000 [9:09:35<175:09:35, 647.41s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|▉                                   | 27/1000 [9:14:30<146:25:23, 541.75s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|█                                   | 28/1000 [9:18:26<121:29:02, 449.94s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|█                                   | 29/1000 [9:26:32<124:17:19, 460.80s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|█                                   | 30/1000 [9:35:00<127:55:12, 474.76s/trial, best loss: -0.022526003591763266]\u001b[A\n","  3%|█                                  | 31/1000 [9:37:34<300:54:07, 1117.90s/trial, best loss: -0.022526003591763266]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 110}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 11%|████████▍                                                                   | 1/9 [9:38:56<77:11:31, 34736.46s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                      | 1/1000 [45:59<765:50:32, 2759.79s/trial, best loss: 0.0026697353372033827]\u001b[A\n","  0%|                                    | 2/1000 [1:10:44<557:08:40, 2009.74s/trial, best loss: 0.0026697353372033827]\u001b[A\n","  0%|                                   | 3/1000 [1:15:49<340:58:14, 1231.19s/trial, best loss: -5.821781140058491e-05]\u001b[A\n","  0%|▏                                  | 4/1000 [1:31:03<306:00:08, 1106.03s/trial, best loss: -5.821781140058491e-05]\u001b[A\n","  0%|▏                                   | 5/1000 [1:40:34<252:22:36, 913.12s/trial, best loss: -5.821781140058491e-05]\u001b[A\n","  1%|▏                                  | 6/1000 [2:04:10<299:21:21, 1084.19s/trial, best loss: -5.821781140058491e-05]\u001b[A\n","  1%|▏                                  | 7/1000 [3:02:43<518:03:33, 1878.16s/trial, best loss: -0.0024733685957478713]\u001b[A\n","  1%|▎                                  | 8/1000 [3:19:42<442:09:05, 1604.58s/trial, best loss: -0.0024733685957478713]\u001b[A\n","  1%|▎                                  | 9/1000 [4:11:09<569:19:56, 2068.21s/trial, best loss: -0.0024733685957478713]\u001b[A\n","  1%|▎                                 | 10/1000 [4:30:16<490:29:18, 1783.59s/trial, best loss: -0.0024733685957478713]\u001b[A\n","  1%|▍                                  | 11/1000 [4:33:49<357:59:58, 1303.13s/trial, best loss: -0.004626429003620425]\u001b[A\n","  1%|▍                                  | 12/1000 [5:20:07<480:46:08, 1751.79s/trial, best loss: -0.004626429003620425]\u001b[A\n","  1%|▍                                  | 13/1000 [5:47:54<473:12:24, 1725.98s/trial, best loss: -0.004626429003620425]\u001b[A\n","  1%|▍                                  | 14/1000 [5:58:57<384:44:58, 1404.76s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▌                                  | 15/1000 [6:28:15<413:33:50, 1511.50s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▌                                  | 16/1000 [7:37:52<632:25:54, 2313.78s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▌                                  | 17/1000 [8:36:52<732:26:36, 2682.40s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▋                                  | 18/1000 [8:50:27<578:37:26, 2121.23s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▋                                  | 19/1000 [9:16:41<533:15:48, 1956.93s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▋                                  | 20/1000 [9:53:47<554:40:30, 2037.58s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▋                                 | 21/1000 [10:22:13<527:06:20, 1938.28s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▋                                 | 22/1000 [11:17:10<637:21:04, 2346.08s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▊                                 | 23/1000 [11:33:01<523:04:58, 1927.43s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▊                                 | 24/1000 [12:25:49<623:27:40, 2299.65s/trial, best loss: -0.004626429003620425]\u001b[A\n","  2%|▊                                 | 25/1000 [12:31:48<465:04:16, 1717.19s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|▉                                 | 26/1000 [13:12:10<521:50:06, 1928.75s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|▉                                 | 27/1000 [13:49:57<548:44:36, 2030.29s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|▉                                 | 28/1000 [14:54:53<699:16:22, 2589.90s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|▉                                 | 29/1000 [15:29:07<655:11:04, 2429.11s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|█                                 | 30/1000 [16:25:10<730:00:12, 2709.29s/trial, best loss: -0.004626429003620425]\u001b[A\n","  3%|█                                 | 31/1000 [17:14:29<538:56:07, 2002.24s/trial, best loss: -0.004626429003620425]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 110}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 22%|████████████████▋                                                          | 2/9 [26:55:06<98:55:16, 50873.81s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                       | 1/1000 [53:53<897:13:15, 3233.23s/trial, best loss: 0.007221743167067141]\u001b[A\n","  0%|                                     | 2/1000 [1:22:46<651:43:17, 2350.90s/trial, best loss: 0.007221743167067141]\u001b[A\n","  0%|                                   | 3/1000 [1:28:55<400:23:13, 1445.73s/trial, best loss: -5.319618368881951e-05]\u001b[A\n","  0%|▏                                  | 4/1000 [1:47:08<361:30:53, 1306.68s/trial, best loss: -5.319618368881951e-05]\u001b[A\n","  0%|▏                                  | 5/1000 [1:58:26<298:30:15, 1080.02s/trial, best loss: -5.319618368881951e-05]\u001b[A\n","  1%|▏                                  | 6/1000 [2:26:27<354:35:59, 1284.27s/trial, best loss: -5.319618368881951e-05]\u001b[A\n","  1%|▏                                  | 7/1000 [3:36:06<615:16:33, 2230.61s/trial, best loss: -0.0014594962653168286]\u001b[A\n","  1%|▎                                  | 8/1000 [3:56:18<525:18:35, 1906.37s/trial, best loss: -0.0014594962653168286]\u001b[A\n","  1%|▎                                  | 9/1000 [4:57:08<674:48:14, 2451.36s/trial, best loss: -0.0014594962653168286]\u001b[A\n","  1%|▎                                 | 10/1000 [5:19:55<582:04:19, 2116.63s/trial, best loss: -0.0014594962653168286]\u001b[A\n","  1%|▍                                  | 11/1000 [5:24:08<424:46:12, 1546.18s/trial, best loss: -0.010019079739428838]\u001b[A\n","  1%|▍                                  | 12/1000 [6:18:57<569:54:22, 2076.58s/trial, best loss: -0.010019079739428838]\u001b[A\n","  1%|▍                                  | 13/1000 [6:51:56<561:11:06, 2046.88s/trial, best loss: -0.010019079739428838]\u001b[A\n","  1%|▍                                  | 14/1000 [7:04:58<456:01:46, 1665.02s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▌                                  | 15/1000 [7:39:53<491:01:06, 1794.58s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▌                                  | 16/1000 [9:01:54<747:41:24, 2735.45s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▌                                 | 17/1000 [10:11:01<862:49:15, 3159.87s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▌                                 | 18/1000 [10:27:02<681:45:00, 2499.29s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▋                                 | 19/1000 [10:58:18<630:03:36, 2312.15s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▋                                 | 20/1000 [11:42:32<657:21:10, 2414.77s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▋                                 | 21/1000 [12:16:36<626:21:52, 2303.28s/trial, best loss: -0.010019079739428838]\u001b[A\n","  2%|▋                                 | 22/1000 [12:35:06<528:27:07, 1945.22s/trial, best loss: -0.011626366881505867]\u001b[A\n","  2%|▊                                 | 23/1000 [12:53:53<461:16:47, 1699.70s/trial, best loss: -0.011626366881505867]\u001b[A\n","  2%|▊                                 | 24/1000 [13:28:00<489:03:42, 1803.92s/trial, best loss: -0.011626366881505867]\u001b[A\n","  2%|▊                                 | 25/1000 [13:46:31<432:16:39, 1596.10s/trial, best loss: -0.011626366881505867]\u001b[A\n","  3%|▉                                 | 26/1000 [14:04:28<389:41:17, 1440.33s/trial, best loss: -0.011892133870957777]\u001b[A\n","  3%|▉                                 | 27/1000 [14:28:45<390:37:16, 1445.26s/trial, best loss: -0.011892133870957777]\u001b[A\n","  3%|▉                                  | 28/1000 [14:46:24<358:55:03, 1329.32s/trial, best loss: -0.01247953852562056]\u001b[A\n","  3%|█                                  | 29/1000 [15:17:36<402:28:41, 1492.20s/trial, best loss: -0.01247953852562056]\u001b[A\n","  3%|█                                  | 30/1000 [16:01:00<491:57:24, 1825.82s/trial, best loss: -0.01247953852562056]\u001b[A\n","  3%|█                                  | 31/1000 [16:13:48<406:00:19, 1508.38s/trial, best loss: -0.01505199825907777]\u001b[A\n","  3%|█                                  | 32/1000 [16:36:31<393:53:52, 1464.91s/trial, best loss: -0.01505199825907777]\u001b[A\n","  3%|█▏                                 | 33/1000 [16:50:01<340:41:12, 1268.33s/trial, best loss: -0.01505199825907777]\u001b[A\n","  3%|█▏                                 | 34/1000 [17:30:20<432:56:20, 1613.44s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▏                                 | 35/1000 [17:55:59<426:33:59, 1591.34s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▎                                 | 36/1000 [18:06:01<346:35:15, 1294.31s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▎                                 | 37/1000 [18:32:13<368:34:42, 1377.86s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▎                                 | 38/1000 [18:50:22<344:59:30, 1291.03s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▎                                 | 39/1000 [18:56:49<272:13:10, 1019.76s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▍                                 | 40/1000 [19:18:15<293:14:28, 1099.65s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▍                                  | 41/1000 [19:28:48<255:40:04, 959.75s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▍                                 | 42/1000 [20:03:13<343:35:26, 1291.15s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▌                                 | 43/1000 [20:25:33<347:12:18, 1306.10s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▌                                 | 44/1000 [20:37:14<298:34:24, 1124.33s/trial, best loss: -0.01505199825907777]\u001b[A\n","  4%|█▌                                 | 45/1000 [21:05:00<341:25:45, 1287.06s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▌                                 | 46/1000 [21:37:28<393:35:59, 1485.28s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▋                                 | 47/1000 [21:55:16<360:03:02, 1360.11s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▋                                 | 48/1000 [22:04:50<297:16:59, 1124.18s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▋                                 | 49/1000 [22:17:45<269:18:33, 1019.47s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▊                                  | 50/1000 [22:23:31<215:40:41, 817.31s/trial, best loss: -0.01505199825907777]\u001b[A\n","  5%|█▊                                 | 51/1000 [22:26:45<417:40:08, 1584.41s/trial, best loss: -0.01505199825907777]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 340}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 33%|████████████████████████▋                                                 | 3/9 [49:23:31<107:38:40, 64586.71s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                     | 1/1000 [19:11<319:30:04, 1151.36s/trial, best loss: -0.0015668709266738468]\u001b[A\n","  0%|                                      | 2/1000 [29:07<228:38:33, 824.76s/trial, best loss: -0.0015668709266738468]\u001b[A\n","  0%|                                      | 3/1000 [31:08<139:22:01, 503.23s/trial, best loss: -0.0015668709266738468]\u001b[A\n","  0%|▏                                      | 4/1000 [37:13<124:07:42, 448.66s/trial, best loss: -0.011530681241657903]\u001b[A\n","  0%|▏                                      | 5/1000 [40:57<101:39:24, 367.80s/trial, best loss: -0.011530681241657903]\u001b[A\n","  1%|▏                                      | 6/1000 [50:15<119:25:42, 432.54s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▎                                    | 7/1000 [1:14:20<210:33:51, 763.38s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▎                                    | 8/1000 [1:21:19<180:11:19, 653.91s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▎                                    | 9/1000 [1:42:21<232:19:19, 843.96s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▎                                   | 10/1000 [1:50:10<200:13:08, 728.07s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▍                                   | 11/1000 [1:51:33<145:48:54, 530.77s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▍                                   | 12/1000 [2:09:58<193:36:16, 705.44s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▍                                   | 13/1000 [2:21:17<191:12:29, 697.42s/trial, best loss: -0.014170456505916529]\u001b[A\n","  1%|▌                                   | 14/1000 [2:25:41<155:10:45, 566.58s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▌                                   | 15/1000 [2:37:43<167:50:18, 613.42s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▌                                   | 16/1000 [3:06:15<258:03:46, 944.13s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▌                                  | 17/1000 [3:30:29<299:36:32, 1097.25s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▋                                   | 18/1000 [3:35:51<235:48:14, 864.45s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▋                                   | 19/1000 [3:46:38<217:43:24, 798.99s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▋                                   | 20/1000 [4:01:53<226:59:00, 833.82s/trial, best loss: -0.014170456505916529]\u001b[A\n","  2%|▊                                   | 21/1000 [4:13:33<215:49:13, 793.62s/trial, best loss: -0.014932117045842741]\u001b[A\n","  2%|▊                                   | 22/1000 [4:25:13<207:58:01, 765.52s/trial, best loss: -0.014932117045842741]\u001b[A\n","  2%|▊                                   | 23/1000 [4:36:50<202:13:25, 745.14s/trial, best loss: -0.014932117045842741]\u001b[A\n","  2%|▊                                   | 24/1000 [4:53:28<222:35:09, 821.01s/trial, best loss: -0.014932117045842741]\u001b[A\n","  2%|▉                                   | 25/1000 [5:01:10<193:09:09, 713.18s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|▉                                   | 26/1000 [5:07:11<164:24:00, 607.64s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|▉                                   | 27/1000 [5:19:01<172:30:44, 638.28s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█                                   | 28/1000 [5:29:57<173:48:24, 643.73s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█                                   | 29/1000 [5:35:12<146:58:32, 544.92s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█                                   | 30/1000 [5:50:30<176:59:07, 656.85s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█                                   | 31/1000 [6:06:00<198:51:59, 738.82s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█▏                                  | 32/1000 [6:12:14<169:15:26, 629.47s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█▏                                  | 33/1000 [6:20:51<159:57:42, 595.51s/trial, best loss: -0.014932117045842741]\u001b[A\n","  3%|█▏                                  | 34/1000 [6:26:14<137:54:52, 513.97s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▎                                  | 35/1000 [6:37:03<148:37:51, 554.48s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▎                                  | 36/1000 [6:47:46<155:34:12, 580.97s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▎                                  | 37/1000 [6:53:49<137:56:07, 515.65s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▎                                  | 38/1000 [7:12:48<187:45:18, 702.62s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▍                                  | 39/1000 [7:17:26<153:33:10, 575.22s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▍                                  | 40/1000 [7:30:58<172:21:35, 646.35s/trial, best loss: -0.014932117045842741]\u001b[A\n","  4%|█▍                                  | 41/1000 [7:37:00<178:09:21, 668.78s/trial, best loss: -0.014932117045842741]\u001b[A\n","{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 500}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 44%|█████████████████████████████████▎                                         | 4/9 [57:05:28<69:29:15, 50031.04s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                      | 1/1000 [21:30<358:10:49, 1290.74s/trial, best loss: -0.001089722228246992]\u001b[A\n","  0%|                                       | 2/1000 [32:44<257:08:15, 927.55s/trial, best loss: -0.001089722228246992]\u001b[A\n","  0%|                                       | 3/1000 [35:00<156:47:17, 566.14s/trial, best loss: -0.001089722228246992]\u001b[A\n","  0%|▏                                      | 4/1000 [41:52<139:51:54, 505.54s/trial, best loss: -0.008272650229984357]\u001b[A\n","  0%|▏                                      | 5/1000 [46:07<114:43:58, 415.11s/trial, best loss: -0.008272650229984357]\u001b[A\n","  1%|▏                                      | 6/1000 [56:42<135:12:36, 489.69s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▎                                    | 7/1000 [1:24:05<239:09:11, 867.02s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▎                                    | 8/1000 [1:32:05<204:53:07, 743.54s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▎                                    | 9/1000 [1:55:59<264:06:07, 959.40s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▎                                   | 10/1000 [2:04:52<227:42:25, 828.03s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▍                                   | 11/1000 [2:06:28<165:52:01, 603.76s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▍                                   | 12/1000 [2:27:22<220:00:40, 801.66s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▍                                   | 13/1000 [2:40:15<217:26:35, 793.11s/trial, best loss: -0.009764202173547232]\u001b[A\n","  1%|▌                                   | 14/1000 [2:45:16<176:30:00, 644.42s/trial, best loss: -0.009764202173547232]\u001b[A\n","  2%|▌                                   | 15/1000 [2:59:01<191:13:50, 698.91s/trial, best loss: -0.009764202173547232]\u001b[A\n","  2%|▌                                  | 16/1000 [3:31:35<294:14:30, 1076.49s/trial, best loss: -0.009764202173547232]\u001b[A\n","  2%|▌                                  | 17/1000 [3:59:07<341:14:26, 1249.71s/trial, best loss: -0.009764202173547232]\u001b[A\n","  2%|▋                                   | 18/1000 [4:05:15<268:33:44, 984.55s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▋                                   | 19/1000 [4:17:33<248:09:14, 910.66s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▋                                   | 20/1000 [4:34:54<258:31:18, 949.67s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▊                                   | 21/1000 [4:43:41<223:45:51, 822.83s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▊                                   | 22/1000 [4:52:42<200:33:27, 738.25s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▊                                   | 23/1000 [5:05:42<203:46:31, 750.86s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▊                                   | 24/1000 [5:18:31<205:02:44, 756.32s/trial, best loss: -0.015657648335507646]\u001b[A\n","  2%|▉                                   | 25/1000 [5:27:49<188:41:37, 696.72s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|▉                                   | 26/1000 [5:31:23<149:20:55, 552.01s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|▉                                   | 27/1000 [5:34:57<121:46:53, 450.58s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|█                                    | 28/1000 [5:37:23<96:57:02, 359.08s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|█                                   | 29/1000 [5:48:54<123:45:37, 458.84s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|█                                   | 30/1000 [5:52:28<103:49:56, 385.36s/trial, best loss: -0.015657648335507646]\u001b[A\n","  3%|█▏                                    | 31/1000 [5:57:00<94:34:45, 351.38s/trial, best loss: -0.01642567270285389]\u001b[A\n","  3%|█▏                                    | 32/1000 [6:03:13<96:10:19, 357.66s/trial, best loss: -0.01642567270285389]\u001b[A\n","  3%|█▏                                   | 33/1000 [6:12:15<110:56:42, 413.03s/trial, best loss: -0.01642567270285389]\u001b[A\n","  3%|█▎                                    | 34/1000 [6:15:58<95:32:38, 356.06s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▎                                    | 35/1000 [6:18:37<79:37:01, 297.02s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▎                                    | 36/1000 [6:24:04<81:55:45, 305.96s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▍                                    | 37/1000 [6:27:16<72:41:08, 271.72s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▍                                    | 38/1000 [6:34:18<84:37:53, 316.71s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▍                                    | 39/1000 [6:36:27<69:34:16, 260.62s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▌                                    | 40/1000 [6:43:52<84:12:16, 315.77s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▌                                    | 41/1000 [6:52:24<99:48:27, 374.67s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▌                                    | 42/1000 [6:53:51<76:42:36, 288.26s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▋                                    | 43/1000 [6:58:36<76:26:25, 287.55s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▋                                    | 44/1000 [7:04:09<79:57:48, 301.12s/trial, best loss: -0.01674694365634799]\u001b[A\n","  4%|█▋                                    | 45/1000 [7:08:10<75:03:25, 282.94s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▋                                    | 46/1000 [7:15:55<89:30:01, 337.74s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▋                                   | 47/1000 [7:23:59<100:58:42, 381.45s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▊                                   | 48/1000 [7:33:30<115:55:55, 438.40s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▊                                    | 49/1000 [7:36:47<96:41:45, 366.04s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▉                                    | 50/1000 [7:41:26<89:42:56, 339.98s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▉                                    | 51/1000 [7:48:33<96:25:48, 365.80s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▉                                   | 52/1000 [7:57:04<107:51:33, 409.59s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▉                                   | 53/1000 [8:18:05<174:54:33, 664.91s/trial, best loss: -0.01674694365634799]\u001b[A\n","  5%|█▉                                   | 54/1000 [8:26:08<147:46:58, 562.39s/trial, best loss: -0.01674694365634799]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 140}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 56%|█████████████████████████████████████████▋                                 | 5/9 [65:33:10<47:44:57, 42974.38s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                      | 1/1000 [24:15<403:55:11, 1455.57s/trial, best loss: -0.003522011504781042]\u001b[A\n","  0%|                                      | 2/1000 [36:52<289:32:29, 1044.44s/trial, best loss: -0.003522011504781042]\u001b[A\n","  0%|                                       | 3/1000 [39:26<176:37:19, 637.75s/trial, best loss: -0.003522011504781042]\u001b[A\n","  0%|▏                                      | 4/1000 [47:09<157:25:54, 569.03s/trial, best loss: -0.010160165940817811]\u001b[A\n","  0%|▏                                      | 5/1000 [51:56<129:06:33, 467.13s/trial, best loss: -0.010160165940817811]\u001b[A\n","  1%|▏                                    | 6/1000 [1:03:49<152:05:03, 550.81s/trial, best loss: -0.011601166182341083]\u001b[A\n","  1%|▎                                    | 7/1000 [1:34:42<269:23:07, 976.62s/trial, best loss: -0.011601166182341083]\u001b[A\n","  1%|▎                                    | 8/1000 [1:43:41<230:41:02, 837.16s/trial, best loss: -0.011601166182341083]\u001b[A\n","  1%|▎                                   | 9/1000 [2:10:41<297:49:18, 1081.90s/trial, best loss: -0.011601166182341083]\u001b[A\n","  1%|▎                                   | 10/1000 [2:20:38<256:22:36, 932.28s/trial, best loss: -0.011601166182341083]\u001b[A\n","  1%|▍                                   | 11/1000 [2:22:25<186:42:54, 679.65s/trial, best loss: -0.011723182405320443]\u001b[A\n","  1%|▍                                  | 12/1000 [2:53:37<286:05:33, 1042.44s/trial, best loss: -0.011723182405320443]\u001b[A\n","  1%|▍                                  | 13/1000 [3:25:55<360:08:33, 1313.59s/trial, best loss: -0.011723182405320443]\u001b[A\n","  1%|▍                                  | 14/1000 [3:31:44<279:59:52, 1022.30s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▌                                   | 15/1000 [3:47:26<273:08:26, 998.28s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▌                                  | 16/1000 [4:24:13<372:16:34, 1361.99s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▌                                  | 17/1000 [4:55:41<415:07:16, 1520.28s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▋                                  | 18/1000 [5:02:36<324:03:43, 1188.01s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▋                                  | 19/1000 [5:16:29<294:39:21, 1081.31s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▋                                  | 20/1000 [5:36:04<302:03:04, 1109.58s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▋                                  | 21/1000 [5:51:13<285:23:31, 1049.45s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▊                                   | 22/1000 [5:56:43<226:25:35, 833.47s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▊                                   | 23/1000 [6:12:35<235:47:41, 868.84s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▊                                   | 24/1000 [6:18:17<192:41:39, 710.76s/trial, best loss: -0.011723182405320443]\u001b[A\n","  2%|▉                                   | 25/1000 [6:23:01<157:50:32, 582.80s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|▉                                   | 26/1000 [6:27:43<133:15:19, 492.53s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|▉                                   | 27/1000 [6:35:15<129:52:45, 480.54s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█                                   | 28/1000 [6:40:30<116:19:48, 430.85s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█                                   | 29/1000 [6:50:22<129:12:45, 479.06s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█                                   | 30/1000 [6:55:09<113:35:48, 421.60s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█                                   | 31/1000 [7:06:22<133:43:37, 496.82s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█▏                                  | 32/1000 [7:12:32<123:25:03, 458.99s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█▏                                  | 33/1000 [7:28:08<161:39:45, 601.85s/trial, best loss: -0.011881959473383663]\u001b[A\n","  3%|█▏                                  | 34/1000 [7:33:01<136:38:14, 509.21s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▎                                  | 35/1000 [7:37:55<119:11:52, 444.68s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▎                                  | 36/1000 [7:47:54<131:29:07, 491.02s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▎                                  | 37/1000 [7:53:46<120:14:15, 449.49s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▎                                  | 38/1000 [7:58:28<106:41:06, 399.24s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▍                                  | 39/1000 [8:04:47<104:55:18, 393.05s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▍                                  | 40/1000 [8:12:49<111:57:06, 419.82s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▍                                  | 41/1000 [8:19:34<110:37:47, 415.29s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▌                                   | 42/1000 [8:23:30<96:09:41, 361.36s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▌                                  | 43/1000 [8:34:04<117:50:15, 443.28s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▌                                  | 44/1000 [8:38:01<101:18:50, 381.52s/trial, best loss: -0.013066377667722895]\u001b[A\n","  4%|█▌                                  | 45/1000 [8:53:59<147:02:04, 554.27s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▋                                  | 46/1000 [9:06:40<163:19:59, 616.35s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▋                                  | 47/1000 [9:14:35<151:54:27, 573.84s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▋                                  | 48/1000 [9:19:49<131:08:39, 495.92s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▊                                  | 49/1000 [9:33:03<154:37:40, 585.34s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▊                                  | 50/1000 [9:48:53<183:20:28, 694.77s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▊                                  | 51/1000 [9:51:19<139:47:48, 530.31s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▊                                 | 52/1000 [10:04:33<160:27:32, 609.34s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▊                                 | 53/1000 [10:24:59<208:55:13, 794.21s/trial, best loss: -0.013066377667722895]\u001b[A\n","  5%|█▉                                 | 54/1000 [10:34:54<185:22:41, 705.46s/trial, best loss: -0.013066377667722895]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 67%|██████████████████████████████████████████████████                         | 6/9 [76:10:16<34:27:59, 41359.79s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                       | 1/1000 [27:46<462:27:41, 1666.53s/trial, best loss: -0.00420939193446912]\u001b[A\n","  0%|                                       | 2/1000 [42:00<329:26:06, 1188.34s/trial, best loss: -0.00420939193446912]\u001b[A\n","  0%|                                        | 3/1000 [44:53<200:45:20, 724.90s/trial, best loss: -0.00420939193446912]\u001b[A\n","  0%|▏                                       | 4/1000 [53:41<179:01:12, 647.06s/trial, best loss: -0.00942428115440408]\u001b[A\n","  0%|▏                                       | 5/1000 [59:04<146:33:12, 530.24s/trial, best loss: -0.00942428115440408]\u001b[A\n","  1%|▏                                    | 6/1000 [1:12:35<172:46:43, 625.76s/trial, best loss: -0.010439424865763103]\u001b[A\n","  1%|▎                                   | 7/1000 [1:47:51<306:59:46, 1112.98s/trial, best loss: -0.010439424865763103]\u001b[A\n","  1%|▎                                    | 8/1000 [1:59:14<268:55:33, 975.94s/trial, best loss: -0.010439424865763103]\u001b[A\n","  1%|▎                                   | 9/1000 [2:36:58<379:29:30, 1378.58s/trial, best loss: -0.010439424865763103]\u001b[A\n","  1%|▎                                  | 10/1000 [3:00:33<382:13:55, 1389.94s/trial, best loss: -0.010439424865763103]\u001b[A\n","  1%|▍                                  | 11/1000 [3:09:51<311:53:54, 1135.32s/trial, best loss: -0.011602635665324379]\u001b[A\n","  1%|▍                                  | 12/1000 [4:47:58<708:19:22, 2580.93s/trial, best loss: -0.011602635665324379]\u001b[A\n","  1%|▍                                  | 13/1000 [5:44:29<774:51:51, 2826.25s/trial, best loss: -0.011602635665324379]\u001b[A\n","  1%|▍                                  | 14/1000 [6:06:40<650:23:13, 2374.64s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▌                                  | 15/1000 [7:06:31<750:01:11, 2741.19s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▌                                 | 16/1000 [9:26:25<1214:20:39, 4442.72s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▌                                | 17/1000 [11:27:45<1446:05:46, 5295.98s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▌                                | 18/1000 [11:55:01<1144:35:23, 4196.05s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▋                                | 19/1000 [12:49:01<1065:12:46, 3909.04s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▋                                | 20/1000 [14:03:46<1111:10:27, 4081.87s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▋                                | 21/1000 [15:01:50<1061:14:52, 3902.44s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▋                                 | 22/1000 [15:23:12<846:29:49, 3115.94s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▊                                 | 23/1000 [16:21:00<874:19:28, 3221.67s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▊                                 | 24/1000 [16:41:45<712:35:28, 2628.41s/trial, best loss: -0.011602635665324379]\u001b[A\n","  2%|▊                                 | 25/1000 [16:58:51<581:42:40, 2147.86s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|▉                                 | 26/1000 [17:39:24<604:13:47, 2233.29s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|▉                                 | 27/1000 [17:58:39<516:10:06, 1909.77s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|▉                                 | 28/1000 [18:53:33<627:47:19, 2325.14s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|▉                                 | 29/1000 [19:56:33<744:51:10, 2761.56s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|█                                 | 30/1000 [20:22:10<645:07:11, 2394.26s/trial, best loss: -0.011602635665324379]\u001b[A\n","  3%|█                                 | 31/1000 [20:52:15<652:23:25, 2423.74s/trial, best loss: -0.011602635665324379]\u001b[A\n","{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 110}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 78%|██████████████████████████████████████████████████████████▎                | 7/9 [97:06:09<29:09:06, 52473.04s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                   | 1/1000 [1:44:44<1743:54:33, 6284.36s/trial, best loss: -0.011047500530663279]\u001b[A\n","  0%|                                   | 2/1000 [2:38:30<1243:29:55, 4485.57s/trial, best loss: -0.011047500530663279]\u001b[A\n","  0%|                                    | 3/1000 [2:49:11<756:05:42, 2730.13s/trial, best loss: -0.011047500530663279]\u001b[A\n","  0%|▏                                   | 4/1000 [3:22:17<673:58:36, 2436.06s/trial, best loss: -0.011047500530663279]\u001b[A\n","  0%|▏                                   | 5/1000 [3:42:30<551:25:41, 1995.12s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▏                                   | 6/1000 [4:33:23<650:13:00, 2354.91s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▏                                  | 7/1000 [6:45:16<1150:44:36, 4171.88s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▎                                   | 8/1000 [7:23:55<987:01:42, 3581.96s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▎                                  | 9/1000 [9:18:51<1271:15:59, 4618.12s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▎                                | 10/1000 [10:01:17<1094:00:54, 3978.24s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▎                                 | 11/1000 [10:08:47<796:14:37, 2898.36s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▍                                | 12/1000 [11:48:12<1051:31:50, 3831.49s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▍                                | 13/1000 [12:48:00<1030:11:20, 3757.53s/trial, best loss: -0.011047500530663279]\u001b[A\n","  1%|▍                                 | 14/1000 [13:10:58<832:21:45, 3039.05s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▌                                 | 15/1000 [14:13:46<891:34:10, 3258.53s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▌                                | 16/1000 [16:41:10<1350:13:37, 4939.86s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▌                                | 17/1000 [18:47:52<1567:26:00, 5740.35s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▌                                | 18/1000 [19:15:55<1233:18:07, 4521.27s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▋                                | 19/1000 [20:12:09<1138:09:50, 4176.75s/trial, best loss: -0.011047500530663279]\u001b[A\n","  2%|▋                                | 20/1000 [21:30:22<1053:48:23, 3871.13s/trial, best loss: -0.011047500530663279]\u001b[A\n","{'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 430}\n"]},{"name":"stderr","output_type":"stream","text":["\r"," 89%|█████████████████████████████████████████████████████████████████▊        | 8/9 [119:15:54<16:59:27, 61167.69s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","  0%|                                                                         | 0/1000 [00:00<?, ?trial/s, best loss=?]\u001b[A\n","  0%|                                   | 1/1000 [1:48:48<1811:34:36, 6528.20s/trial, best loss: -0.008877642287229759]\u001b[A\n","  0%|                                   | 2/1000 [2:44:57<1294:35:05, 4669.85s/trial, best loss: -0.008877642287229759]\u001b[A\n","  0%|                                    | 3/1000 [2:56:24<789:36:12, 2851.13s/trial, best loss: -0.008877642287229759]\u001b[A\n","  0%|▏                                   | 4/1000 [3:31:17<706:03:54, 2552.04s/trial, best loss: -0.008877642287229759]\u001b[A\n","  0%|▏                                   | 5/1000 [3:52:52<580:06:31, 2098.89s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▏                                   | 6/1000 [4:45:50<680:44:13, 2465.45s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▏                                  | 7/1000 [7:06:07<1216:48:25, 4411.39s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▎                                  | 8/1000 [7:47:09<1044:32:46, 3790.69s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▎                                  | 9/1000 [9:49:37<1349:37:40, 4902.79s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▎                                | 10/1000 [10:34:26<1160:17:37, 4219.25s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▎                                 | 11/1000 [10:42:27<844:51:47, 3075.34s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▍                                | 12/1000 [12:27:23<1112:52:34, 4055.01s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▍                                | 13/1000 [13:33:22<1103:46:27, 4025.92s/trial, best loss: -0.008877642287229759]\u001b[A\n","  1%|▍                                 | 14/1000 [13:58:33<894:38:26, 3266.44s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▌                                 | 15/1000 [15:09:08<973:34:45, 3558.26s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▌                                | 16/1000 [17:52:42<1487:17:53, 5441.34s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▌                                | 17/1000 [20:13:25<1732:13:57, 6343.88s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▌                                | 18/1000 [20:44:24<1362:48:45, 4996.05s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▋                                | 19/1000 [21:47:20<1261:35:45, 4629.71s/trial, best loss: -0.008877642287229759]\u001b[A\n","  2%|▋                                | 20/1000 [23:13:06<1137:42:31, 4179.34s/trial, best loss: -0.008877642287229759]\u001b[A\n","{'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 430}\n"]},{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████████████████████| 9/9 [143:12:04<00:00, 57280.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["-0.003120370577061937\n"]}],"source":["# cross_validate 적용\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from hyperopt import hp\n","from hyperopt import STATUS_OK\n","from hyperopt.early_stop import no_progress_loss\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from tqdm import tqdm\n","import joblib\n","\n","a = '2004|2005|2006|2007|2008|2009|2010|2011|2012|2013|2014|2015|2016|2017|2018|2019|2020'\n","sse = 0\n","ya0 = []\n","tk0 = []\n","ym0 = []\n","ya1 = []\n","\n","for i in tqdm(range(9)): \n","    # tX = X[ym.str.contains(a[:24+5*i])]\n","    # vX = X[ym.str.contains(a[25+5*i:39+5*i])]\n","    tvX = X[ym.str.contains(a[:39+5*i])]\n","    tvym = ym[ym.str.contains(a[:39+5*i])]\n","    oX = X[ym.str.contains(a[40+5*i:44+5*i])]\n","    # ty = y[ym.str.contains(a[:24+5*i])]\n","    Vy = y[ym.str.contains(a[25+5*i:39+5*i])]\n","    tvy = y[ym.str.contains(a[:39+5*i])]\n","    oy = y[ym.str.contains(a[40+5*i:44+5*i])]\n","    otk = tk[ym.str.contains(a[40+5*i:44+5*i])]\n","    oym = ym[ym.str.contains(a[40+5*i:44+5*i])]\n","    \n","    # 하이퍼파라미터 검색 공간 설정\n","    gbrt_search_space = {\n","        'learning_rate' : hp.choice('learning_rate', [0.00001, 0.0001, 0.001, 0.01, 0.1]),\n","        'max_depth' : hp.quniform('max_depth', 1, 6, 1),\n","        'n_estimators' : hp.quniform('n_estimators', 100, 500, 10),\n","    }\n","    \n","    # 목적 함수 정의\n","    def objective_func(search_space):\n","        gbrt = GradientBoostingRegressor(\n","            loss='huber', \n","            alpha=0.999, \n","            n_estimators = int(search_space['n_estimators']),\n","            learning_rate = search_space['learning_rate'],\n","            max_depth = int(search_space['max_depth']),\n","            random_state = 1\n","        )\n","        \n","        d = 0\n","        \n","        for j in range(3): # 마지막 3년만 valid로 사용\n","            tX = X[ym.str.contains(a[:24+5*(j+i)])]\n","            vX = X[ym.str.contains(a[25+5*(j+i):29+5*(j+i)])]\n","            ty = y[ym.str.contains(a[:24+5*(j+i)])]\n","            vy = y[ym.str.contains(a[25+5*(j+i):29+5*(j+i)])]\n","            \n","            # for문에 필요한 key를 미리 만듦\n","            ym_temp = vX['yearmonth'].reset_index(drop=True) # t = ym_temp==k를 위해 reset index\n","            key_yearmonth = dict.fromkeys(ym_temp)\n","            \n","            # vy의 index를 reset\n","            vy.reset_index(drop=True, inplace=True) # r = r*(vy[sort[-d:].index].mean()+100)/100를 위해 reset index\n","            \n","            # 년도, 티커 드랍\n","            tX = tX.drop(['yearmonth', 'Ticker'], axis=1)\n","            vX = vX.drop(['yearmonth', 'Ticker'], axis=1)\n","            \n","            # fitting\n","            gbrt.fit(tX, ty)\n","            \n","            # r2oos 계산         \n","            y_pred = pd.Series(gbrt.predict(vX).reshape(-1,)) # sort_values() 사용을 위해 변환\n","            d = d + sum((vy-y_pred)**2) \n","\n","        e = sum(Vy**2)\n","        r2oos = 1-(d/e)\n","        new_loss = r2oos*(-1)\n","\n","        return {\n","            'loss':new_loss,\n","            'status':STATUS_OK\n","        }\n","    \n","    # fmin()을 사용하여 최적 하이퍼 파라미터 찾기\n","    from hyperopt import fmin, tpe, Trials\n","    import warnings\n","    warnings.filterwarnings('ignore')\n","\n","    trial_val = Trials() # 결과 저장\n","    \n","    best = fmin(\n","        fn=objective_func,\n","        space=gbrt_search_space,\n","        algo=tpe.suggest,\n","        max_evals=1000,    # 최대 반복 횟수 지정\n","        trials=trial_val,\n","        return_argmin=False, # hp.choice의 경우 값 대신 index를 반환함 \n","        early_stop_fn=no_progress_loss(20), # 30회 동안 개선되지 않으면 조기중지\n","        # https://github.com/hyperopt/hyperopt/issues/689\n","        rstate=np.random.default_rng(42) # https://github.com/hyperopt/hyperopt/issues/838\n","    )\n","    \n","    # 정수형 하이퍼 파라미터 값이 뒤에 .0이 붙어서 실수형으로 반환됨을 유의하기!\n","    best['n_estimators'] = int(best['n_estimators'])\n","    best['max_depth'] = int(best['max_depth'])\n","    print(best) \n","    \n","    reg0 = GradientBoostingRegressor(\n","        loss = 'huber', \n","        alpha = 0.999,\n","        random_state = 1,\n","        **best)\n","    \n","    import warnings\n","    warnings.filterwarnings('ignore')\n","    \n","    tvX = tvX.drop(['yearmonth', 'Ticker'], axis=1)\n","    oX = oX.drop(['yearmonth', 'Ticker'], axis=1)\n","    \n","    reg0.fit(tvX, tvy)\n","    \n","    yy0 = reg0.predict(oX)\n","    ya0 = ya0 + oy.tolist()\n","    ya1 = ya1 + yy0.tolist()\n","    tk0 = tk0 + otk.tolist()\n","    ym0 = ym0 + oym.tolist()\n","    joblib.dump(reg0,'GBRT_bayesian_r2oos_last3_'+str(i)+'.pkl')\n","    sse = sse + sum((oy-yy0)**2)\n","\n","oyy = y[ym.str.contains(a[40:84])]\n","e = sum(oyy**2)\n","r2oos = 1-(sse/e)\n","print(r2oos)\n","    \n","GBRT = pd.DataFrame({'real':ya0,'predict':ya1,'ticker':tk0,'yearmonth':ym0})\n","GBRT.to_csv('GBRT_bayesian_r2oos.csv')    "]},{"cell_type":"code","execution_count":null,"id":"a57ff547","metadata":{"id":"a57ff547"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","GBRT = pd.read_csv(\"GBRT_bayesian_r2oos.csv\")"]},{"cell_type":"code","execution_count":null,"id":"8e0a9701","metadata":{"id":"8e0a9701"},"outputs":[],"source":["ya0 = pd.Series(GBRT['real'])\n","ya1 = pd.Series(GBRT['predict'])\n","tk0 = pd.Series(GBRT['ticker'])\n","ym0 = pd.Series(GBRT['yearmonth'])\n","\n","r1 = []\n","for i in list(dict.fromkeys(ym0)):\n","    t = ym0==i\n","    d = round(len(ya1[t])/10)\n","    sort = ya1[t].sort_values()\n","    r1.append(ya0[sort[-d:].index].mean())\n","\n","rr1 = 1\n","rgbrt1 = [1]\n","for i in r1:\n","    rr1 = rr1*(i+100)/100\n","    rgbrt1.append(rr1)"]},{"cell_type":"code","execution_count":null,"id":"2568e1ac","metadata":{"id":"2568e1ac","outputId":"e2fcaf36-9ce2-475a-bfcc-925a0486c1ac"},"outputs":[{"data":{"text/plain":["27.77815124446899"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["rgbrt1[-1]"]},{"cell_type":"code","execution_count":null,"id":"881e1d45","metadata":{"id":"881e1d45"},"outputs":[],"source":["r1 = []\n","r2 = []\n","for i in list(dict.fromkeys(ym0)):\n","    t = ym0==i\n","    d = round(len(ya1[t])/10)\n","    sort = ya1[t].sort_values()\n","    r1.append(ya0[sort[-d:].index].mean())\n","    r2.append(ya0[sort[0:d].index].mean())"]},{"cell_type":"code","execution_count":null,"id":"5e81e0c6","metadata":{"id":"5e81e0c6","outputId":"4c895677-a1ee-4c6c-cd43-ea0b59cdc4e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["year: 0 test 수익률: 1.5743718514920493\n","year: 1 test 수익률: 1.5234573193313339\n","year: 2 test 수익률: 1.7142262378324884\n","year: 3 test 수익률: 1.519993217272505\n","year: 4 test 수익률: 1.8580196299859524\n","year: 5 test 수익률: 1.197174590519485\n","year: 6 test 수익률: 1.1391020443282107\n","year: 7 test 수익률: 1.1562081251344234\n","year: 8 test 수익률: 1.51722330598476\n"]}],"source":["for i in range(9):\n","    rr1 = 1\n","    for j in r1[0+i*12:12+i*12]:\n","        rr1 = rr1*(j+100)/100\n","    print(\"year:\" ,i, \"test 수익률:\", rr1)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}